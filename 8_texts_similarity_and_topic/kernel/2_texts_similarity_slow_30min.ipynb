{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# This is version, that compares all words of 2 texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8865208947358074"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# nltk.download('popular') # run it once\n",
    "# nltk.download('punkt')   # run it once (try without it)\n",
    "import numpy as np\n",
    "import nltk\n",
    "from nltk.corpus import wordnet as wn\n",
    "import pandas as pd\n",
    "\n",
    "# doc1 = 'This is a function to test document_path_similarity.'\n",
    "# doc2 = 'Use this function to see if your code in doc_to_synsets \\\n",
    "# and similarity_score is correct!'\n",
    "with open('plato.txt', 'r', encoding='utf8') as f: doc1 = f.read()\n",
    "with open('socrates.txt', 'r', encoding='utf8') as f: doc2 = f.read()\n",
    "\n",
    "\n",
    "\n",
    "def convert_tag(tag):\n",
    "    tag_dict = {'N': 'n', 'J': 'a', 'R': 'r', 'V': 'v'} # Convert the tag given by nltk.pos_tag to the tag used by wordnet.synsets\n",
    "    try: return tag_dict[tag[0]]\n",
    "    except KeyError: return None\n",
    "    \n",
    "    \n",
    "# input: 'This is a function to test document_path_similarity.'\n",
    "# output: # [Synset('be.v.01'), Synset('angstrom.n.01'), Synset('function.n.01'), Synset('test.v.01')]\n",
    "def text_to_synsets_list(doc): # convert string to similar string with changed words (to similar or delete, if there is not similar)\n",
    "    words = nltk.word_tokenize(doc)                     # ['This', 'is', 'a', 'function', 'to', 'test', 'document_path_similarity', '.']\n",
    "    words_n_pos = nltk.pos_tag(words)                   # [('This', 'DT'), ('is', 'VBZ'), ('a', 'DT'), ('function', 'NN'), ('to', 'TO'), ('test', 'VB'), ('document_path_similarity', 'NN'), ('.', '.')]\n",
    "    poses = [y for x,y in words_n_pos]                  # ['DT', 'VBZ', 'DT', 'NN', 'TO', 'VB', 'NN', '.']\n",
    "    # just renames by first letter\n",
    "    wntag = [convert_tag(x) for x in poses]             # [None, 'v', None, 'n', None, 'v', 'n', None]\n",
    "    #mix words and PoS first letters\n",
    "    ans = list(zip(words,wntag))                       # [('This', None), ('is', 'v'), ('a', None), ('function', 'n'), ('to', None), ('test', 'v'), ('document_path_similarity', 'n'), ('.', None)]\n",
    "    # similar words from WordNet\n",
    "    synsets = [wn.synsets(x,y) for x,y in ans]          # [[], [Synset('be.v.01'),  Synset('exist.v.01'),  Synset('equal.v.01'),...\n",
    "    # remove empty groups and all synsets expect 1 in each groups\n",
    "    final = [val[0] for val in synsets if len(val) > 0] \n",
    "    return final # [Synset('be.v.01'), Synset('angstrom.n.01'), Synset('function.n.01'), Synset('test.v.01')]\n",
    "\n",
    "\n",
    "def compare_2_sysnet_lists(s1, s2):\n",
    "    scores_best =[]\n",
    "    for i in s1:\n",
    "        #print(i, 'first')        # Synset('be.v.01')  /n  Synset('angstrom.n.01')  /n  Synset('function.n.01')  /n  Synset('test.v.01')\n",
    "        scores_all =[]\n",
    "        for j in s2:\n",
    "            # print(j) # 4 loops of: Synset('use.v.01')   Synset('function.n.01')   Synset('see.v.01')   Synset('code.n.01')   Synset('inch.n.01')   Synset('be.v.01')   Synset('correct.a.01')\n",
    "            # if words are similar - path_similarity returns 1 (be and be)\n",
    "            #print(i.path_similarity(j)) # 0.33 0.14 0.25 0.14 0.11 1.0 0.33 None 0.1 None 0.1 0.25 None None None ...\n",
    "            similarity = i.path_similarity(j)\n",
    "            if (similarity != None): scores_all.append(similarity)\n",
    "        if scores_all: scores_best.append(max(scores_all))\n",
    "    # scores_best                     # [1.0, 0.25, 1.0, 0.2]      \n",
    "    return sum(scores_best)/len(scores_best) # 0.6125\n",
    "    \n",
    "s1 = text_to_synsets_list(doc1) # [be angstrom function test]\n",
    "s2 = text_to_synsets_list(doc2) # [use function see code inch be correct]\n",
    "compare_2_sysnet_lists(s1, s2) #0.8865208947358074"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Synset('star.n.01'),\n",
       " Synset('ace.n.03'),\n",
       " Synset('star.n.03'),\n",
       " Synset('star.n.04'),\n",
       " Synset('star.n.05'),\n",
       " Synset('headliner.n.01'),\n",
       " Synset('asterisk.n.01'),\n",
       " Synset('star_topology.n.01')]"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get word synsets\n",
    "from nltk.corpus import wordnet as wn\n",
    "# available parts of speech'n', 'a', 'r', 'v'\n",
    "wn.synsets('star', 'n')             # [Synset('star.n.01'), Synset('ace.n.03'), Synset('star.n.03'), Synset('star.n.04'), Synset('star.n.05'), Synset('headliner.n.01'), Synset('asterisk.n.01'), Synset('star_topology.n.01')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# evaluate their similarity\n",
    "word_0 = wn.synsets('star', 'n')[0] # Synset('star.n.01')\n",
    "word_1 = wn.synsets('star', 'n')[0] # Synset('ace.n.03')\n",
    "word_0.path_similarity(word_1)      #0.1111111111111111"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
