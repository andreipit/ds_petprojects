{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Main speed increaser - we compare topics, not whole texts\n",
    "# result - 30 sec (0.67) instead 30 min (0.88)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# nltk.download('popular') # run it once\n",
    "# nltk.download('punkt')   # run it once (try without it)\n",
    "import numpy as np\n",
    "import nltk\n",
    "from nltk.corpus import wordnet as wn\n",
    "import pandas as pd\n",
    "\n",
    "# doc1 = 'This is a function to test document_path_similarity.'\n",
    "# doc2 = 'Use this function to see if your code in doc_to_synsets \\\n",
    "# and similarity_score is correct!'\n",
    "with open('../input/plato.txt', 'r', encoding='utf8') as f: doc1 = f.read()\n",
    "with open('../input/socrates.txt', 'r', encoding='utf8') as f: doc2 = f.read()\n",
    "with open('../input/airplane.txt', 'r', encoding='utf8') as f: doc3 = f.read()\n",
    "\n",
    "def convert_tag(tag):\n",
    "    tag_dict = {'N': 'n', 'J': 'a', 'R': 'r', 'V': 'v'} # Convert the tag given by nltk.pos_tag to the tag used by wordnet.synsets\n",
    "    try: return tag_dict[tag[0]]\n",
    "    except KeyError: return None\n",
    "    \n",
    "def text_to_synsets_list(doc): # convert string to similar string with changed words (to similar or delete, if there is not similar)\n",
    "    # input: 'This is a function to test document_path_similarity.'\n",
    "    # output: # [Synset('be.v.01'), Synset('angstrom.n.01'), Synset('function.n.01'), Synset('test.v.01')]\n",
    "    words = nltk.word_tokenize(doc)                     # ['This', 'is', 'a', 'function', 'to', 'test', 'document_path_similarity', '.']\n",
    "    words_n_pos = nltk.pos_tag(words)                   # [('This', 'DT'), ('is', 'VBZ'), ('a', 'DT'), ('function', 'NN'), ('to', 'TO'), ('test', 'VB'), ('document_path_similarity', 'NN'), ('.', '.')]\n",
    "    poses = [y for x,y in words_n_pos]                  # ['DT', 'VBZ', 'DT', 'NN', 'TO', 'VB', 'NN', '.']\n",
    "    # just renames by first letter\n",
    "    wntag = [convert_tag(x) for x in poses]             # [None, 'v', None, 'n', None, 'v', 'n', None]\n",
    "    #mix words and PoS first letters\n",
    "    ans = list(zip(words,wntag))                       # [('This', None), ('is', 'v'), ('a', None), ('function', 'n'), ('to', None), ('test', 'v'), ('document_path_similarity', 'n'), ('.', None)]\n",
    "    # similar words from WordNet\n",
    "    synsets = [wn.synsets(x,y) for x,y in ans]          # [[], [Synset('be.v.01'),  Synset('exist.v.01'),  Synset('equal.v.01'),...\n",
    "    # remove empty groups and all synsets expect 1 in each groups\n",
    "    final = [val[0] for val in synsets if len(val) > 0] \n",
    "    return final # [Synset('be.v.01'), Synset('angstrom.n.01'), Synset('function.n.01'), Synset('test.v.01')]\n",
    "\n",
    "def compare_2_sysnet_lists(s1, s2):\n",
    "    scores_best =[]\n",
    "    for i in s1:\n",
    "        #print(i, 'first')        # Synset('be.v.01')  /n  Synset('angstrom.n.01')  /n  Synset('function.n.01')  /n  Synset('test.v.01')\n",
    "        scores_all =[]\n",
    "        for j in s2:\n",
    "            # print(j) # 4 loops of: Synset('use.v.01')   Synset('function.n.01')   Synset('see.v.01')   Synset('code.n.01')   Synset('inch.n.01')   Synset('be.v.01')   Synset('correct.a.01')\n",
    "            # if words are similar - path_similarity returns 1 (be and be)\n",
    "            #print(i.path_similarity(j)) # 0.33 0.14 0.25 0.14 0.11 1.0 0.33 None 0.1 None 0.1 0.25 None None None ...\n",
    "            similarity = i.path_similarity(j)\n",
    "            if (similarity != None): scores_all.append(similarity)\n",
    "        if scores_all: scores_best.append(max(scores_all))\n",
    "    # scores_best                     # [1.0, 0.25, 1.0, 0.2]      \n",
    "    return sum(scores_best)/len(scores_best) # 0.6125\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5099787370815394"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pickle\n",
    "import gensim #anaconda prompt -> pip install -U gensim\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "def find_topics_of_string(s, topic_count):\n",
    "    data = [s]\n",
    "    vect = CountVectorizer(min_df=0, max_df=1, stop_words='english', token_pattern='(?u)\\\\b\\\\w\\\\w\\\\w+\\\\b')\n",
    "    X = vect.fit_transform(data)\n",
    "    corpus = gensim.matutils.Sparse2Corpus(X, documents_columns=False)\n",
    "    id_map = dict((v, k) for k, v in vect.vocabulary_.items())\n",
    "    ldamodel = gensim.models.ldamodel.LdaModel(corpus, id2word=id_map, num_topics=1, passes=25, random_state=34) # wait too long\n",
    "    return ldamodel.print_topics(num_topics=1, num_words=topic_count) #[0][1].split('+')[0].split('*')[1]\n",
    "    \n",
    "def clean_topics(top): #[(0,   '0.031*\"plato\" + 0.011*\"socrates\")] => ['plato', 'socrates']\n",
    "    return [x.split('*')[1].replace('\"', '').rstrip() for x in top[0][1].split('+')]    \n",
    "    \n",
    "doc1 = clean_topics(find_topics_of_string(doc1, 1000)) #['plato', 'socrates', 'dialogues', 'forms', 'republic']\n",
    "doc2 = clean_topics(find_topics_of_string(doc2, 1000))\n",
    "doc3 = clean_topics(find_topics_of_string(doc3, 1000))\n",
    "doc1 =  ''.join(e+' ' for e in doc1).rstrip()  #'plato socrates dialogues forms republic'\n",
    "doc2 =  ''.join(e+' ' for e in doc2).rstrip()  \n",
    "doc3 =  ''.join(e+' ' for e in doc3).rstrip()  \n",
    "s1 = text_to_synsets_list(doc1) # synsets: [be angstrom function test]\n",
    "s2 = text_to_synsets_list(doc2) \n",
    "s3 = text_to_synsets_list(doc3)\n",
    "\n",
    "#compare_2_sysnet_lists(s1, s2) #0.6789118246687038  plato vs socrates\n",
    "compare_2_sysnet_lists(s1, s3) #0.5099787370815394   plato vs airplane"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
